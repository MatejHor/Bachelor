{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import HDF5Matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import keras.callbacks as cb\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Conv2D, MaxPool2D, Flatten, LeakyReLU, Concatenate, GlobalAveragePooling2D, UpSampling2D\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import cv2\n",
    "import pprint\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "import src.model as my_model\n",
    "import src.pcam_loader as data\n",
    "import src.adaptive_model as am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Show if tensorflow can run with GPU\n",
    "# Run tensorflow keras on multiple core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12308808593558015536\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4854028697\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2074148839406745717\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5\"\n",
      "]\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# config = tf.ConfigProto(device_count={\"CPU\": 8})\n",
    "# tensorflow.compat.v1.keras.backend.set_session(tf.Session(config=config))\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import h5py\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataset(path, dataset_type, image_size=256, pixel_shift=16):\n",
    "    x_images = os.listdir(path + '/Label/')\n",
    "    x_images.pop()\n",
    "    dataframe = h5py.File(dataset_type + \"_dataset.hdf5\", \"w\")\n",
    "    image_shape = (image_size, image_size, 1)\n",
    "\n",
    "    for image in x_images:\n",
    "        for y in range(0, 512 - image_size, pixel_shift):\n",
    "            for x in range(0, 512 - image_size, pixel_shift):\n",
    "                picture = Image.open(path + re.sub('_label','',image))\n",
    "                label_path = path + 'Label/' + image\n",
    "                cut_name = re.sub('.PNG', '', image) + '_' + str(x) + '_'+ str(y) + '.PNG'\n",
    "                cut_picture = picture.crop((x, y, image_size + x, image_size + y))\n",
    "                cut_picture = np.asarray(cut_picture)\n",
    "\n",
    "                data = dataframe.create_dataset(cut_name, shape=image_shape, data=cut_picture)\n",
    "                picture_label = Image.open(label_path)\n",
    "                cut_picture_label = picture_label.crop((x, y, image_size + x, image_size + y))\n",
    "\n",
    "                black_count = [1 for row in np.asarray(cut_picture_label) for column in row if not column == 0]\n",
    "                if len(black_count) == 0:\n",
    "                    data.attrs['class_type'] = 0\n",
    "                else:\n",
    "                    data.attrs['class_type'] = 1\n",
    "\n",
    "    dataframe.close()\n",
    "    \n",
    "\n",
    "# create_dataset('./data/class6/Train/', 'Train', 96)\n",
    "# create_dataset('./data/class6/Test/', 'Test', 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DAGM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_type, path=None):\n",
    "    if path:\n",
    "        dataset_type = os.path.join(path, dataset_type)\n",
    "    dataset = h5py.File(dataset_type + '_dataset.hdf5', 'r')\n",
    "    dataset_name = list(dataset)\n",
    "\n",
    "    y = []\n",
    "    x = []\n",
    "    for name in dataset_name:\n",
    "        data = dataset[name]\n",
    "        y.append(data.attrs['class_type'])\n",
    "        x_item = data[:]\n",
    "        x.append(x_item)\n",
    "\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(len(y),1)\n",
    "    x = np.array(x)\n",
    "    dataset.close()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset('Train')\n",
    "x_test, y_test = load_dataset('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_length = round(len(x_test)/2)\n",
    "\n",
    "x_valid = np.array(x_test[x_valid_length:])\n",
    "x_test = np.array(x_test[:x_valid_length])\n",
    "\n",
    "y_valid = y_test[x_valid_length:]\n",
    "y_test = y_test[:x_valid_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of train (56108, 96, 96, 1) 56108 (56108, 1)\n",
      "Shape of valid (22646, 96, 96, 1) 22646 (22646, 1)\n",
      "Shape of test (22646, 96, 96, 1) 22646 (22646, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(meta_train.head(5), '\\n')\n",
    "# print(meta_train.info())\n",
    "\n",
    "print('\\n' + 'Shape of train', x_train.shape,  len(y_train), y_train.shape)\n",
    "print('Shape of valid', x_valid.shape,  len(y_valid), y_valid.shape)\n",
    "print('Shape of test', x_test.shape, len(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load pcam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matho\\Anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py:60: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f = h5py.File(datapath)\n"
     ]
    }
   ],
   "source": [
    "# Load data from /User/Username/.keras/datasets/pcam\n",
    "dataset = data.load_data()\n",
    "x_train, y_train, meta_train =  dataset[0]\n",
    "x_valid, y_valid, meta_valid =  dataset[1]\n",
    "x_test, y_test, meta_test =  dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train[:])\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_valid = np.array(y_valid[:])\n",
    "y_valid = y_valid.reshape(-1, 1)\n",
    "y_test = np.array(y_test[:])\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as ShowPicture\n",
    "ShowPicture(filename='./data/obrazky/image.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(meta_train.head(5), '\\n')\n",
    "print(meta_train.info())\n",
    "\n",
    "# Shape of train, valid and test input are the same, don't need to preprocess\n",
    "print('\\n' + 'Shape of train', x_train.shape,  len(y_train), y_train.shape)\n",
    "print('Shape of valid', x_valid.shape,  len(y_valid), y_valid.shape)\n",
    "print('Shape of test', x_test.shape, len(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 10\n",
    "num_classes = 2\n",
    "shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer with shape of data\n",
    "input_layer = am.input_layer(shape)\n",
    "model_name = 'adaptive_backpropagation332.h5'\n",
    "\n",
    "# layers = am.unet_layer(input_layer, 7, 16) \n",
    "# layers = am.unet_layer(input_layer, 5, 16) \n",
    "# layers = am.unet_layer(input_layer, 3, 16) \n",
    "\n",
    "# layers = am.unet_layer(input_layer, 7, 32)\n",
    "# layers = am.unet_layer(input_layer, 5, 32)\n",
    "layers = am.unet_layer(input_layer, 3, 32)\n",
    "\n",
    "# layers = am.unet_layer(input_layer, 7, 64) \n",
    "# layers = am.unet_layer(input_layer, 5, 64) \n",
    "# layers = am.unet_layer(input_layer, 3, 64) \n",
    "\n",
    "# Use Unet architecture as main model\n",
    "outputs_layer = am.unet_model(layers)\n",
    "\n",
    "# Output layer\n",
    "outputs_layer = am.flatten_layer(outputs_layer)\n",
    "outputs_layer = am.output_layer(outputs_layer)\n",
    "\n",
    "# Define model \n",
    "model = am.define_model(input_layer, outputs_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer with shape of data\n",
    "input_layer = am.input_layer(shape)\n",
    "model_name = 'adaptive_autoencoder364.h5'\n",
    "\n",
    "# layers = am.encoder_layer(input_layer, 7, 16) \n",
    "# layers = am.encoder_layer(input_layer, 5, 16) \n",
    "# layers = am.encoder_layer(input_layer, 3, 16) \n",
    "\n",
    "# layers = am.encoder_layer(input_layer, 7, 32) \n",
    "# layers = am.encoder_layer(input_layer, 5, 32) \n",
    "# layers = am.encoder_layer(input_layer, 3, 32)\n",
    "\n",
    "# layers = am.encoder_layer(input_layer, 7, 64) \n",
    "# layers = am.encoder_layer(input_layer, 5, 64) \n",
    "layers = am.encoder_layer(input_layer, 3, 64) \n",
    "\n",
    "# Use Unet architecture as main model\n",
    "outputs_layer = am.unet_model(layers)\n",
    "\n",
    "# Output layer\n",
    "outputs_layer = am.flatten_layer(outputs_layer)\n",
    "outputs_layer = am.output_layer(outputs_layer)\n",
    "\n",
    "# Define model \n",
    "model = am.define_model(input_layer, outputs_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabor kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer with shape of data\n",
    "input_layer = am.input_layer(shape)\n",
    "model_name = 'adaptive_gabor532.h5'\n",
    "\n",
    "# layers = am.gabor_layer(input_layer, 9, 16) \n",
    "# layers = am.gabor_layer(input_layer, 7, 16) \n",
    "# layers = am.gabor_layer(input_layer, 5, 16) \n",
    "\n",
    "# layers = am.gabor_layer(input_layer, 9, 32) \n",
    "# layers = am.gabor_layer(input_layer, 7, 32)\n",
    "layers = am.gabor_layer(input_layer, 5, 32)\n",
    "# Test loss: 0.31318365948966587 Precision: 0.9474299550056458 Accuracy: 0.9329683184623718 Recall: 0.9474299550056458 TruePositives: 756883.8125 FalsePositives: 41999.8125 FalseNegatives: 41999.8125 F1_score 0.940143476461619\n",
    "\n",
    "# layers = am.gabor_layer(input_layer, 9, 64) \n",
    "# layers = am.gabor_layer(input_layer, 7, 64) \n",
    "# layers = am.gabor_layer(input_layer, 5, 64) \n",
    "\n",
    "# Use Unet architecture as main model\n",
    "outputs_layer = am.unet_model(layers)\n",
    "\n",
    "# Output layer\n",
    "outputs_layer = am.flatten_layer(outputs_layer)\n",
    "outputs_layer = am.output_layer(outputs_layer)\n",
    "\n",
    "# Define model \n",
    "model = am.define_model(input_layer, outputs_layer)\n",
    "\n",
    "# Add filters from gabor function\n",
    "model.layers[1].set_weights(am.gabor_filter(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "from keras import applications\n",
    "model_name = 'adaptive_transfer.h5'\n",
    "\n",
    "# Use ImageNet as first 'layers'\n",
    "\n",
    "# base_model= applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = shape)\n",
    "# Test loss: 0.6934362644678913 Precision: 0.4979618191719055 Accuracy: 0.500213623046875 Recall: 0.4979618191719055 TruePositives: 1476714.625 FalsePositives: 1488804.75 FalseNegatives: 1488804.75 F1_score 0.49908513116502834 \n",
    "base_model= applications.resnet.ResNet152(weights = \"imagenet\", include_top=False, input_shape = shape)\n",
    "layer = base_model.output\n",
    "\n",
    "# Use Unet architecture as main model\n",
    "# outputs_layer = am.unet_model(layer)\n",
    "\n",
    "# Output layer\n",
    "outputs_layer = am.transfer_layer(layer)\n",
    "outputs_layer = am.output_layer(outputs_layer)\n",
    "\n",
    "# Define model \n",
    "model = am.define_model(base_model.input, outputs_layer)\n",
    "    \n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[15:]:\n",
    "    layer.trainable=True\n",
    "    \n",
    "# for layer in model.layers[:20]:\n",
    "#     layer.trainable=False\n",
    "# for layer in model.layers[30:]:\n",
    "#     layer.trainable=True\n",
    "    \n",
    "# for layer in model.layers[:25]:\n",
    "#     layer.trainable=False\n",
    "# for layer in model.layers[25:]:\n",
    "#     layer.trainable=True\n",
    "\n",
    "# for layer in model.layers[:30]:\n",
    "#     layer.trainable=False\n",
    "# for layer in model.layers[30:]:\n",
    "#     layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    result = true_positives / (possible_positives + K.epsilon())\n",
    "    return result\n",
    "\n",
    "\n",
    "def my_own_preci(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    result = true_positives / (predicted_positives + K.epsilon())\n",
    "    return result\n",
    "\n",
    "\n",
    "def f1_score_metrics(y_true, y_pred):\n",
    "    precision_result = precision(y_true, y_pred)\n",
    "    recall_result = recall(y_true, y_pred)\n",
    "    return 2*((precision_result*recall_result)/(precision_result+recall_result+K.epsilon()))\n",
    "\n",
    "\n",
    "def f1_score_evaluate(precision, recall):\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 96, 96, 32)   320         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 96, 96, 32)   128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 96, 96, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 48, 48, 32)   0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 48, 48, 32)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 48, 48, 16)   4624        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 48, 48, 16)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 48, 48, 16)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 24, 24, 16)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 24, 24, 16)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 24, 24, 32)   4640        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 24, 24, 32)   128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 24, 24, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 32)   0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 12, 12, 32)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 12, 12, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 6, 6, 64)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 6, 6, 64)     0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 6, 6, 128)    73856       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 6, 6, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 6, 6, 128)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 3, 3, 128)    0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 3, 3, 128)    0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 3, 3, 256)    295168      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 3, 3, 256)    1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 256)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 6, 6, 128)    295040      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6, 6, 256)    0           conv2d_transpose_5[0][0]         \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 6, 6, 256)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 6, 6, 128)    295040      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 6, 6, 128)    512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 6, 6, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 12, 12, 64)   73792       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 12, 12, 128)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 12, 12, 128)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 64)   73792       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 24, 24, 32)   18464       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 24, 24, 64)   0           conv2d_transpose_7[0][0]         \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 24, 24, 64)   0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 24, 24, 32)   18464       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 24, 24, 32)   128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 24, 24, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 48, 48, 16)   4624        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 48, 48, 32)   0           conv2d_transpose_8[0][0]         \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 48, 48, 32)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 48, 48, 16)   4624        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 48, 48, 16)   64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 48, 48, 16)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 48, 48, 1)    17          activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2304)         0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            4610        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,188,643\n",
      "Trainable params: 1,187,107\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    cb.callbacks.ModelCheckpoint(model_name, save_best_only=True)\n",
    "#     cb.callbacks.EarlyStopping(monitor = 'val_loss'),\n",
    "#     cb.callbacks.CSVLogger('model.csv', separator=',', append=False),\n",
    "#     cb.tensorboard_v1.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "]\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(), \n",
    "              metrics=[\n",
    "                  tensorflow.keras.metrics.Precision(),\n",
    "                  'accuracy',\n",
    "                  tensorflow.keras.metrics.Recall(),\n",
    "                  tensorflow.keras.metrics.TruePositives(),\n",
    "                  tensorflow.keras.metrics.FalsePositives(),\n",
    "                  tensorflow.keras.metrics.FalseNegatives()\n",
    "                      ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56108 samples, validate on 22646 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    to_categorical(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_valid, to_categorical(y_valid)),\n",
    "    shuffle='batch',\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True, \n",
    "    workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('eop_' + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "f1_score = f1_score_evaluate(test_eval[2], test_eval[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0],end=' ')\n",
    "print('Precision:', test_eval[1],end=' ')\n",
    "print('Accuracy:', test_eval[2],end=' ')\n",
    "print('Recall:', test_eval[3],end=' ')\n",
    "print('TruePositives:', test_eval[4],end=' ')\n",
    "print('FalsePositives:', test_eval[5],end=' ')\n",
    "print('FalseNegatives:', test_eval[6],end=' ')\n",
    "print('F1_score', f1_score,end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on model ( real evaluate ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, verbose=0, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My precision', my_own_preci(to_categorical(y_test), y_pred))\n",
    "print('My recall', recall(to_categorical(y_test), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graf from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name of model is', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['recall'])\n",
    "# plt.plot(history.history['precision'])\n",
    "# plt.plot(history.history['val_precision'])\n",
    "# plt.plot(history.history['val_recall'])\n",
    "# plt.title('recall precision')\n",
    "# plt.ylabel('recall, precision')\n",
    "# plt.xlabel('epochs')\n",
    "# plt.legend(['recall', 'precision'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('val_precision precision')\n",
    "plt.ylabel('val_precision, precision')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['val_precision', 'precision'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "plt.title('val_recall recall')\n",
    "plt.ylabel('val_recall, recall')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['val_recall', 'recall'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['true_positives'])\n",
    "plt.plot(history.history['val_true_positives'])\n",
    "plt.title('val_true_positives true_positives')\n",
    "plt.ylabel('val_true_positives, true_positives')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['val_true_positives', 'true_positives'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['false_positives'])\n",
    "plt.plot(history.history['val_false_positives'])\n",
    "plt.title('val_false_positives false_positives')\n",
    "plt.ylabel('val_false_positives, false_positives')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['val_false_positives', 'false_positives'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['false_negatives'])\n",
    "plt.plot(history.history['val_false_negatives'])\n",
    "plt.title('val_false_negatives false_negatives')\n",
    "plt.ylabel('val_false_negatives, false_negatives')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['val_false_negatives', 'false_negatives'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positives = 0\n",
    "test_negatives = 0\n",
    "pred_positives = 0\n",
    "pred_negatives = 0\n",
    "for value in to_categorical(y_test):\n",
    "#     print(value)\n",
    "    if value[0] == 0:\n",
    "        test_positives += 1\n",
    "    else:\n",
    "        test_negatives += 1\n",
    "        \n",
    "for value in K.round(K.clip(y_pred, 0, 1)):\n",
    "#     print(value)\n",
    "    if value[0] == 0:\n",
    "        pred_positives += 1\n",
    "    else:\n",
    "        pred_negatives += 1        \n",
    "\n",
    "print(test_positives)\n",
    "print(test_negatives)\n",
    "print(pred_positives)\n",
    "print(pred_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {}\n",
    "custom_objects[\"precision\"] = 'tensorflow.keras.metrics.Precision'\n",
    "custom_objects[\"recall\"] = 'tensorflow.keras.metrics.Recall'\n",
    "custom_objects[\"true_positives\"] = 'tensorflow.keras.metrics.TruePositives'\n",
    "custom_objects[\"false_positives\"] = 'tensorflow.keras.metrics.FalsePositives'\n",
    "custom_objects[\"false_negatives\"] = 'tensorflow.keras.metrics.FalseNegatives'\n",
    "\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_name, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = loaded_model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "f1_score = f1_score_evaluate(test_eval[2], test_eval[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0],end=' ')\n",
    "print('Precision:', test_eval[1],end=' ')\n",
    "print('Accuracy:', test_eval[2],end=' ')\n",
    "print('Recall:', test_eval[3],end=' ')\n",
    "print('TruePositives:', test_eval[4],end=' ')\n",
    "print('FalsePositives:', test_eval[5],end=' ')\n",
    "print('FalseNegatives:', test_eval[6],end=' ')\n",
    "print('F1_score', f1_score,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(x_test.astype('float16'), verbose=0, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My precision', my_own_preci(to_categorical(y_test), y_pred))\n",
    "print('My recall', recall(to_categorical(y_test), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positives = 0\n",
    "test_negatives = 0\n",
    "pred_positives = 0\n",
    "pred_negatives = 0\n",
    "for value in to_categorical(y_test):\n",
    "#     print(value)\n",
    "    if value[0] == 0:\n",
    "        test_positives += 1\n",
    "    else:\n",
    "        test_negatives += 1\n",
    "        \n",
    "for value in K.round(K.clip(y_pred, 0, 1)):\n",
    "#     print(value)\n",
    "    if value[0] == 0:\n",
    "        pred_positives += 1\n",
    "    else:\n",
    "        pred_negatives += 1        \n",
    "\n",
    "print(test_positives)\n",
    "print(test_negatives)\n",
    "print(pred_positives)\n",
    "print(pred_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
